{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59LOhQgv4kxj"
   },
   "source": [
    "In this notebook, we study the features of the nela dataset, using the subset of the dataset (4 newsources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DhhG2OJ4RUY6"
   },
   "outputs": [],
   "source": [
    "# Some features can be calculated using: https://github.com/RyleeThompson/unbiasMe/blob/master/helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IxjcL_0T6IOe"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'subset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f88168a14c01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"subset.csv\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Or just use the full csv file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0msources\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"CNN\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Fox News\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"BBC\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Xinhua\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mreadibility\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\" TTR\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"SMOG\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"FKE\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"wordlen\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\news-bias-analysis\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\news-bias-analysis\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\news-bias-analysis\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\news-bias-analysis\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\news-bias-analysis\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\news-bias-analysis\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\news-bias-analysis\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'subset.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "df = pd.read_csv(\"subset.csv\") # Or just use the full csv file\n",
    "sources = [\"CNN\",\"Fox News\",\"BBC\", \"Xinhua\"]\n",
    "readibility = [\" TTR\",\"SMOG\", \"FKE\",\"wordlen\"]\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6AF55q04i-r"
   },
   "source": [
    "Below is the list of features within the dataset, we will choose a few to study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1636937829290,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "57nn_XCmK8FO",
    "outputId": "9939f184-8b3f-4af0-d162-8c57bf8cb3ee"
   },
   "outputs": [],
   "source": [
    "for c in df.columns: \n",
    "  print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmiJrvx6BQvV"
   },
   "source": [
    "## Study of Readibility\n",
    "First we will look at several measures of difficulty of a text:\n",
    "\n",
    "1) TTR\n",
    "\n",
    "2) SMOG\n",
    "\n",
    "3) FKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1636937831607,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "mCbveDYsH0T9",
    "outputId": "c21e5984-5745-4801-ee08-947ce43a113d"
   },
   "outputs": [],
   "source": [
    "sns.displot(df, x= \" TTR\", kind=\"kde\",hue = \" source\",multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIm3omIC5ye3"
   },
   "source": [
    "Here is a plot of the TTR feature distribution for each news source. TTR of a text is defined as $$\\frac{ \\# unique\\_words}{\\# words}$$. TTR measures the lexical diversity, which can help measure the difficulty of a text. The higher the TTR, the harder it can be for non-native speakers/new speakers to read atext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1636937834146,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "TFp6edZ2-Lns",
    "outputId": "0314ae5d-0472-46f3-c6ef-9d31d05a05eb"
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "for source in sources:\n",
    "    res[source] = df[df[\" source\"] == source][\" TTR\"].mean()\n",
    "res = {k: v for k, v in sorted(res.items(), key=lambda item: item[1])}\n",
    "sns.barplot(x=list(res.keys()), y=list(res.values())).set_title(\"Mean of TTR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "executionInfo": {
     "elapsed": 787,
     "status": "ok",
     "timestamp": 1636937835583,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "aZxIx8qa4zyX",
    "outputId": "54805f5d-dae6-4135-b18b-2dcfb4a5a539"
   },
   "outputs": [],
   "source": [
    "sns.displot(df, x= \"SMOG\", kind=\"kde\",hue = \" source\",multiple=\"stack\")\n",
    "f.set_titles(\"SMOG Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1636937837067,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "GnZCB5is7EsE",
    "outputId": "96281964-b48e-460f-afde-d2af6b912b25"
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "for source in sources:\n",
    "    res[source] = df[df[\" source\"] == source][\"SMOG\"].mean()\n",
    "res = {k: v for k, v in sorted(res.items(), key=lambda item: item[1])}\n",
    "sns.barplot(x=list(res.keys()), y=list(res.values())).set_title(\"Mean of SMOG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdzHKrj6B-3p"
   },
   "source": [
    "Description of SMOG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "executionInfo": {
     "elapsed": 816,
     "status": "ok",
     "timestamp": 1636937839386,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "bz4Z4bTK3rWH",
    "outputId": "77e2db39-0437-47da-ad79-13fb7fd3fb63"
   },
   "outputs": [],
   "source": [
    "f = sns.displot(df, x= \"FKE\", kind=\"kde\",hue = \" source\",multiple=\"stack\")\n",
    "f.set_titles(\"FKE Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1636937840347,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "jvZ-luQ6CBLr",
    "outputId": "c2352615-107a-45b3-e4a6-ec4dd590f626"
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "for source in sources:\n",
    "    res[source] = df[df[\" source\"] == source][\"FKE\"].mean()\n",
    "res = {k: v for k, v in sorted(res.items(), key=lambda item: item[1])}\n",
    "sns.barplot(x=list(res.keys()), y=list(res.values())).set_title(\"Mean of FKE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "executionInfo": {
     "elapsed": 807,
     "status": "ok",
     "timestamp": 1636937844202,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "O4Ccu7-yCKee",
    "outputId": "ff5232b3-fd3e-4b54-faf3-115da397ff0e"
   },
   "outputs": [],
   "source": [
    "f= sns.displot(df, x= \"wordlen\", kind=\"kde\",hue = \" source\",multiple=\"stack\")\n",
    "f.set_titles(\"Avg WordLen Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1636937845287,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "uIWu2bqxC9D0",
    "outputId": "0a62837d-ebc7-451d-f9a1-e77805da3fdb"
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "for source in sources:\n",
    "    res[source] = df[df[\" source\"] == source][\"wordlen\"].mean()\n",
    "res = {k: v for k, v in sorted(res.items(), key=lambda item: item[1])}\n",
    "sns.barplot(x=list(res.keys()), y=list(res.values())).set_title(\"Mean of Avg WordLen\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYBX4nyuGVtL"
   },
   "source": [
    "Here is the plot for the average word length of the articles per each newsource\n",
    "\n",
    "**Some Takeaways**\n",
    "\n",
    "\n",
    "1.   Xinhua is the hardest to read: longest avg word len per article, highest FKE,SMOG, and TTR Scores\n",
    "2.   Fox is harder to read than CNN on all metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ac1N8VWEQL4"
   },
   "outputs": [],
   "source": [
    "r_frame = df[readibility]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 1451,
     "status": "ok",
     "timestamp": 1636938978280,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "biPQRdWAGmi7",
    "outputId": "46130226-9a05-4a4b-aeda-0b4351e362f7"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data=r_frame, x=\"wordlen\", y=\"FKE\", kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 1682,
     "status": "ok",
     "timestamp": 1636938470082,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "ioRgkZ5LHZwj",
    "outputId": "c1a83089-ffba-4e96-a9bd-53809e18e06e"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data=r_frame, x=\"wordlen\", y=\"SMOG\", kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 1323,
     "status": "ok",
     "timestamp": 1636939254608,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "t9NzA1dyLqah",
    "outputId": "cf844507-35ef-4413-fb02-309061ab4806"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data=r_frame, x=\"FKE\", y=\"SMOG\", kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 1651,
     "status": "ok",
     "timestamp": 1636939277106,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "qiSfKpWpLuFI",
    "outputId": "4a15d4ed-c3fd-46b5-9ca6-7be0350ca0e1"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data=r_frame, x=\"SMOG\", y=\" TTR\", kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 1374,
     "status": "ok",
     "timestamp": 1636939353583,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "EGXX4bgrMDZc",
    "outputId": "92de305b-b627-4571-8db6-8131f0d450b7"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data=r_frame, x=\"wordlen\", y=\" TTR\", kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mKx8feRJfph"
   },
   "source": [
    "**Notable correlation for readibility features**\n",
    "\n",
    "\n",
    "1.   Longer avg wordlen --> Higher SMOG value\n",
    "2.   Longer avg wordlen --> Higher SKE value\n",
    "3.   Higher FKE --> Higher SMOG\n",
    "\n",
    "\n",
    "Interestingly, SMOG and wordlen are quite uncorelalted with TTR score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We will look at the sentiment distribution next\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "executionInfo": {
     "elapsed": 655,
     "status": "ok",
     "timestamp": 1636939800538,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "aL5Rr5viM2bt",
    "outputId": "e17df51c-ec53-458a-d2c9-666f08a5c629"
   },
   "outputs": [],
   "source": [
    "f= sns.displot(df, x= \" wneg_count\", kind=\"kde\",hue = \" source\",multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kW5HB4c7N_s3"
   },
   "source": [
    "wneg_count can be calculated using:  wneg_count = float(sum([tokens.count(n) for n in wneg]))/len(tokens)\n",
    "\n",
    "In other words, go through each token and count the total number of tokens that belong to the negative class and divide that by total number of tokens. The idea is the same for wpos_count and wneu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1636939918845,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "P8CKo2RSNXeU",
    "outputId": "8f56a89d-f1e0-4efb-8685-053800f238c1"
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "for source in sources:\n",
    "    res[source] = df[df[\" source\"] == source][\" wneg_count\"].mean()\n",
    "res = {k: v for k, v in sorted(res.items(), key=lambda item: item[1])}\n",
    "sns.barplot(x=list(res.keys()), y=list(res.values())).set_title(\"Mean of Average Negative Words per Article\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "executionInfo": {
     "elapsed": 779,
     "status": "ok",
     "timestamp": 1636940026143,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "V0dTNmQINtfd",
    "outputId": "9e1df5ac-4f64-488e-bfc6-ddde7bedbfcf"
   },
   "outputs": [],
   "source": [
    "f= sns.displot(df, x= \" wpos_count\", kind=\"kde\",hue = \" source\",multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1636940041140,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "ny6BvxnmOo1_",
    "outputId": "4885936c-9221-4fc5-df5c-e297348da456"
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "for source in sources:\n",
    "    res[source] = df[df[\" source\"] == source][\" wpos_count\"].mean()\n",
    "res = {k: v for k, v in sorted(res.items(), key=lambda item: item[1])}\n",
    "sns.barplot(x=list(res.keys()), y=list(res.values())).set_title(\"Mean of Average Positive Words per Article\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "executionInfo": {
     "elapsed": 661,
     "status": "ok",
     "timestamp": 1636940506314,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "Tg-oj7IxQbee",
    "outputId": "971da700-1aff-43ad-a085-3d4890f88560"
   },
   "outputs": [],
   "source": [
    "f= sns.displot(df, x= \"vad_neg\", kind=\"kde\",hue = \" source\",multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1636940537159,
     "user": {
      "displayName": "Jeff Wirojwatanakul",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04081898060782895841"
     },
     "user_tz": 480
    },
    "id": "DlyOe-SiQdR4",
    "outputId": "7f7e8581-98a5-4fcc-b91c-62bf4d9321b2"
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "for source in sources:\n",
    "    res[source] = df[df[\" source\"] == source][\"vad_neg\"].mean()\n",
    "res = {k: v for k, v in sorted(res.items(), key=lambda item: item[1])}\n",
    "sns.barplot(x=list(res.keys()), y=list(res.values())).set_title(\"Mean of sentiment calculated using Vader\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypeIUkUfQpkj"
   },
   "source": [
    "**Takeaways**\n",
    "\n",
    "Firstly: using basic negative word counts\n",
    "\n",
    "1.   CNN uses, on average, more positive words per article than Fox News.\n",
    "2.   Fox uses, on average, more negative words per article than CNN.\n",
    "\n",
    "Note # of positive + negative != # of tokens, there are neutral tokens/words as well\n",
    "\n",
    "\n",
    "Secondly using Vader:\n",
    "By using vader to calculate the sentiment on the articles, we observe similar things: Fox has more negative articles than CNN"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPwejMLn72+kABTfv85JDRn",
   "collapsed_sections": [],
   "name": "nela_features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
